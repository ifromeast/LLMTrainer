{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6fc069c",
   "metadata": {},
   "source": [
    "## streaming_llm å®žè·µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57c50a5-98e1-4b0c-b197-06e45a49d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from streaming_llm.utils import load, download_url, load_jsonl\n",
    "from streaming_llm.enable_streaming_llm import enable_streaming_llm\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def greedy_generate(model, tokenizer, input_ids, past_key_values, max_gen_len):\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        past_key_values=past_key_values,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    past_key_values = outputs.past_key_values\n",
    "    pred_token_idx = outputs.logits[:, -1, :].argmax(dim=-1).unsqueeze(1)\n",
    "    generated_ids = [pred_token_idx.item()]\n",
    "    pos = 0\n",
    "    for _ in range(max_gen_len - 1):\n",
    "        outputs = model(\n",
    "            input_ids=pred_token_idx,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=True,\n",
    "        )\n",
    "        past_key_values = outputs.past_key_values\n",
    "        pred_token_idx = outputs.logits[:, -1, :].argmax(dim=-1).unsqueeze(1)\n",
    "        generated_ids.append(pred_token_idx.item())\n",
    "        generated_text = (\n",
    "            tokenizer.decode(\n",
    "                generated_ids,\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True,\n",
    "                spaces_between_special_tokens=False,\n",
    "            )\n",
    "            .strip()\n",
    "            .split(\" \")\n",
    "        )\n",
    "\n",
    "        now = len(generated_text) - 1\n",
    "        if now > pos:\n",
    "            print(\" \".join(generated_text[pos:now]), end=\" \", flush=True)\n",
    "            pos = now\n",
    "\n",
    "        if pred_token_idx == tokenizer.eos_token_id:\n",
    "            break\n",
    "    print(\" \".join(generated_text[pos:]), flush=True)\n",
    "    return past_key_values\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def streaming_inference(model, tokenizer, prompts, kv_cache=None, max_gen_len=1000):\n",
    "    past_key_values = None\n",
    "    for idx, prompt in enumerate(prompts):\n",
    "        prompt = \"USER: \" + prompt + \"\\n\\nASSISTANT: \"\n",
    "        print(\"\\n\" + prompt, end=\"\")\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        input_ids = input_ids.to(model.device)\n",
    "        seq_len = input_ids.shape[1]\n",
    "        if kv_cache is not None:\n",
    "            space_needed = seq_len + max_gen_len\n",
    "            past_key_values = kv_cache.evict_for_space(past_key_values, space_needed)\n",
    "\n",
    "        past_key_values = greedy_generate(\n",
    "            model, tokenizer, input_ids, past_key_values, max_gen_len=max_gen_len\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda4fa97-52b6-4c38-b4fc-24deca2d3005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:15<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartRecentKVCache: 4, 2000\n",
      "\n",
      "USER: Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions.\n",
      "\n",
      "ASSISTANT: ðŸŒ´ðŸŒŠðŸï¸ Hawaii: A Cultural Paradise ðŸŒºðŸŒžðŸ„â€â™€ï¸\n",
      "\n",
      "Hawaii, the land of Aloha, is a tropical paradise that offers a unique blend of natural beauty, rich culture, and endless adventures. Recently, I had the pleasure of visiting this enchanting archipelago, and I must say, it exceeded all my expectations. From the stunning beaches to the vibrant local traditions, Hawaii is a true gem that every traveler should experience at least once in their lifetime.\n",
      "\n",
      "ðŸŒŠ Surf's Up in Waikiki ðŸŒŠ\n",
      "\n",
      "No trip to Hawaii is complete without spending some time in Waikiki, the iconic beach town that's home to some of the world's most famous surf spots. I was thrilled to take a surfing lesson with a local company that not only taught me the basics but also gave me a glimpse into the Hawaiian surf culture. It was amazing to see how surfing is not just a sport, but a "
     ]
    }
   ],
   "source": [
    "model, tokenizer = load(\"lmsys/vicuna-13b-v1.5\") \n",
    "test_filepath = os.path.join(\"streamingllm_mt_data.jsonl\")\n",
    "\n",
    "list_data = load_jsonl(test_filepath)\n",
    "prompts = []\n",
    "for sample in list_data:\n",
    "    prompts += sample[\"turns\"]\n",
    "\n",
    "kv_cache = enable_streaming_llm(model, start_size=4, recent_size=2000)\n",
    "streaming_inference(model, tokenizer, prompts, kv_cache,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f993f-8d54-48ae-86dc-bff7076f2cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zzd-env",
   "language": "python",
   "name": "zzd-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
